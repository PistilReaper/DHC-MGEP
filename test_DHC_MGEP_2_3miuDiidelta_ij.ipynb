{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f8564dd-31ce-4dc6-baf6-a49c3dcc05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% import modules\n",
    "import geppy as gep\n",
    "from deap import creator, base, tools\n",
    "import numpy as np\n",
    "import random\n",
    "import operator \n",
    "import pickle\n",
    "from fractions import Fraction\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import sympy as sp\n",
    "import copy\n",
    "import DHC_MGEP as dm\n",
    "\n",
    "# For reproduction\n",
    "s = 0\n",
    "random.seed(s)\n",
    "np.random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70abb123-bcab-442b-af39-481f19c27d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% define functions for tensor operators \n",
    "def tensor_add(a, b):\n",
    "    if isinstance(a, np.ndarray) and isinstance(b, np.ndarray) and a.shape == b.shape:\n",
    "        return a + b\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def tensor_sub(a, b):\n",
    "    if isinstance(a, np.ndarray) and isinstance(b, np.ndarray) and a.shape == b.shape:\n",
    "        return a - b\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def tensor_inner_product(a, b):\n",
    "    if isinstance(a, np.ndarray) and isinstance(b, np.ndarray) and a.shape == b.shape:\n",
    "        result = np.empty_like(a)\n",
    "        for i in range(a.shape[0]):\n",
    "            result[i] = np.matmul(a[i], b[i])\n",
    "        return result\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def p_(tensor):\n",
    "    '''\n",
    "    need to define a global variable ---- plasmid_library through function Y_pretend\n",
    "    '''\n",
    "    if isinstance(tensor, np.ndarray):\n",
    "        scalar = eval(plasmid_library.pop(0))\n",
    "        if isinstance(scalar, np.ndarray):\n",
    "            return scalar[:, None] * tensor\n",
    "        return tensor * scalar\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def p_symbol(tensor):\n",
    "    '''\n",
    "    need to define a global variable ---- plasmid_library through function: my_compile\n",
    "    '''\n",
    "    scalar_expression = plasmid_library.pop(0)\n",
    "    return tensor * scalar_expression\n",
    "        \n",
    "# define a protected division to avoid dividing by zero\n",
    "def protected_div(x1, x2):\n",
    "    if abs(x2) < 1e-10:\n",
    "        return 1\n",
    "    return x1 / x2\n",
    "\n",
    "\n",
    "def add(a,b):\n",
    "    return a + b\n",
    "\n",
    "def sub(a,b):\n",
    "    return a - b\n",
    "\n",
    "def mul(a,b):\n",
    "    return a * b\n",
    "\n",
    "symbolic_function_map = {\n",
    "        'tensor_add': operator.add,\n",
    "        'tensor_sub': operator.sub,\n",
    "        'tensor_inner_product': operator.mul,\n",
    "        'p_': p_symbol,\n",
    "        operator.add.__name__: operator.add,\n",
    "        operator.sub.__name__: operator.sub,\n",
    "        operator.mul.__name__: operator.mul,\n",
    "        'protected_div': operator.truediv,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24234f6c-b26c-4e64-a771-b6e97c2e13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% generate data\n",
    "\n",
    "# target equation: tau_ij = 2*miu*S_ij - (2/3)*miu*D_ii*delta_ij\n",
    "#                         = miu*(u_i__j+u_j__i) - (2/3)*miu*D_ii*delta_ij\n",
    "# 即静压为0时的牛顿流体本构方程\n",
    "data = scio.loadmat('data/Taylor_vortex_flow.mat')\n",
    "\n",
    "u_x = data['u_x'] # u_x__x, s-1\n",
    "u_y = data['u_y'] # u_x__y, s-1\n",
    "v_x = data['v_x'] # u_y__x, s-1\n",
    "v_y = data['v_y'] # u_y__y, s-1\n",
    "\n",
    "# subsample\n",
    "indices = np.random.choice(u_x.shape[0], 100, replace=False)\n",
    "u_x = u_x[indices]\n",
    "u_y = u_y[indices]\n",
    "v_x = v_x[indices]\n",
    "v_y = v_y[indices]\n",
    "\n",
    "u_i__j = np.stack((np.stack((u_x, u_y), axis=1), np.stack((v_x, v_y), axis=1)), axis=2)\n",
    "u_j__i = np.stack((np.stack((u_x, v_x), axis=1), np.stack((u_y, v_y), axis=1)), axis=2)\n",
    "u_i__j = u_i__j.reshape((len(u_x), 2, 2))\n",
    "u_j__i = u_j__i.reshape((len(u_x), 2, 2))\n",
    "\n",
    "S_ij = 0.5 * (u_i__j + u_j__i)\n",
    "Omega_ij = 0.5 * (u_i__j - u_j__i)\n",
    "\n",
    "df_c = 1.399e-05 # Diffusion coefficient\n",
    "miu = 2.079e-5 # Viscosity coefficient\n",
    "\n",
    "#u_ij的两个主不变量\n",
    "D_ii = u_x + v_y\n",
    "det___D_ij = u_x * v_y - u_y * v_x\n",
    "\n",
    "shape = (len(u_x),1)\n",
    "ones = np.ones(shape, dtype = np.float64)\n",
    "zeros = np.zeros(shape, dtype = np.float64)\n",
    "delta_ij = np.stack((np.stack((ones, zeros), axis=1), np.stack((zeros, ones), axis=1)), axis=2)\n",
    "delta_ij = delta_ij.reshape((len(u_x), 2, 2))\n",
    "                            \n",
    "tau_ij = - (2/3)*miu*D_ii[:, None]*delta_ij\n",
    "\n",
    "def add_noise(array, snr):\n",
    "    mean_power = np.mean(array**2)\n",
    "    noise_power = mean_power / (10**(snr / 10))\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), array.shape)\n",
    "    noisy_array = array + noise\n",
    "    return noisy_array\n",
    "\n",
    "def add_gaussian_noise(array, mean=0, std=1):\n",
    "    noise = np.random.normal(mean, std, array.shape)\n",
    "    return array + noise\n",
    "\n",
    "def add_uniform_noise(array, low=-1, high=1):\n",
    "    noise = np.random.uniform(low, high, array.shape)\n",
    "    return array + noise\n",
    "\n",
    "Y = tau_ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9fe562-d945-423d-9fe6-56222ad002d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Assign number tags\n",
    "\n",
    "# Assign prime number tags to base dimensions\n",
    "L,M,T,I,Theta,N,J = 2,3,5,7,11,13,17\n",
    "\n",
    "# Derive the tags for dirived physical quantities according to their dimensions\n",
    "# Note that the tags are always in the form of fractions, instead of floats, which avoids introducing any truncation error. \n",
    "# Therefore, we use 'Fraction' function here.\n",
    "dict_of_dimension = {'S_ij':Fraction(1,T),\n",
    "                     'Omega_ij':Fraction(1,T),\n",
    "                     # 'u_i,j':Fraction(1,T),\n",
    "                     # 'u_j,i':Fraction(1,T),\n",
    "                     'delta_ij':Fraction(1),\n",
    "                     'D_ii':Fraction(1,T),\n",
    "                     'det___D_ij':Fraction(1,(T**2)),\n",
    "                     'miu':Fraction(M,L*T),\n",
    "                     'df_c':Fraction((L**2),T)} \n",
    "\n",
    "# Assign number tags to taget variable\n",
    "target_dimension = Fraction(M,L*((T)**(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d089b9-6b75-4ffe-bbac-d5ae95d6cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Creating the primitives set\n",
    "# Define the operators\n",
    "host_pset = gep.PrimitiveSet('Host', input_names=['S_ij','Omega_ij','delta_ij'])\n",
    "host_pset.add_function(tensor_add, 2)\n",
    "host_pset.add_function(tensor_sub, 2)\n",
    "host_pset.add_function(tensor_inner_product, 2)\n",
    "host_pset.add_function(p_, 1)\n",
    "\n",
    "\n",
    "plasmid_pset = gep.PrimitiveSet('Plasmid', input_names=['D_ii','det___D_ij'])\n",
    "plasmid_pset.add_symbol_terminal('df_c', df_c)\n",
    "plasmid_pset.add_symbol_terminal('miu', miu)\n",
    "plasmid_pset.add_function(operator.add, 2)\n",
    "plasmid_pset.add_function(operator.sub, 2)\n",
    "plasmid_pset.add_function(operator.mul, 2)\n",
    "plasmid_pset.add_function(protected_div, 2)\n",
    "plasmid_pset.add_rnc_terminal() # Add random numerical constants (RNC).\n",
    "# %% Create the individual and population\n",
    "\n",
    "# Define the indiviudal class, a subclass of gep.Chromosome\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1,))  # weights=(-1,)/weights=(1,) means to minimize/maximize the objective (fitness).\n",
    "creator.create(\"Host_Individual\", gep.Chromosome, fitness=creator.FitnessMax, plasmid=[])\n",
    "creator.create(\"Plasmid_Individual\", gep.Chromosome) \n",
    "\n",
    "# Register the individual and population creation operations\n",
    "h = 15           # head length\n",
    "n_genes = 2      # number of genes in a chromosome\n",
    "r = 15          # length of the RNC array\n",
    "# enable_ls = True # whether to apply the linear scaling technique\n",
    "\n",
    "toolbox = gep.Toolbox()\n",
    "\n",
    "toolbox.register('host_gene_gen', gep.Gene, pset=host_pset, head_length=h)\n",
    "toolbox.register('host_individual', creator.Host_Individual, gene_gen=toolbox.host_gene_gen, n_genes=n_genes, linker=tensor_add)\n",
    "toolbox.register(\"host_population\", tools.initRepeat, list, toolbox.host_individual)\n",
    "\n",
    "def random_float(a, b):\n",
    "    # Generate floating-point numbers that retain five decimal places\n",
    "    num = random.uniform(a, b)\n",
    "    num = round(num, 5)\n",
    "    return num\n",
    "    \n",
    "toolbox.register('rnc_gen', random_float, a=-5, b=5)   # each RNC is random float within [-0.2, 0.2]\n",
    "toolbox.register('plasmid_gene_gen', gep.GeneDc, pset=plasmid_pset, head_length=h, rnc_gen=toolbox.rnc_gen, rnc_array_length=r)\n",
    "toolbox.register('plasmid_individual', creator.Plasmid_Individual, gene_gen=toolbox.plasmid_gene_gen, n_genes=n_genes, linker=operator.add)\n",
    "toolbox.register(\"plasmid_population\", dm.plasmid_generate, toolbox.plasmid_individual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebe35bb-93ed-49cd-a4c9-009dfcee89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_compile(Individual, usage):\n",
    "    global plasmid_library\n",
    "    if usage == 'show':\n",
    "        plasmid_library = []\n",
    "        for plasmid in Individual.plasmid:\n",
    "            scalar_expression = gep.simplify(plasmid, symbolic_function_map)\n",
    "            plasmid_library.append(scalar_expression)\n",
    "        tensor_expression = gep.simplify(Individual, symbolic_function_map)\n",
    "        return str(tensor_expression)\n",
    "    else:\n",
    "        raise ValueError(\"usage should be 'dimensional_verification','fitness_evaluation', or 'show'. \")\n",
    "\n",
    "def Y_pretend(individual):\n",
    "    global plasmid_library\n",
    "    plasmid_library = [str(plasmid) for plasmid in individual.plasmid]\n",
    "    host_str = str(individual)\n",
    "    return eval(host_str)\n",
    "\n",
    "def dimensional_verification(individual, dict_of_dimension, target_dimension):\n",
    "    plasmid_library = [str(plasmid).replace('\\t','').replace('\\n','')\n",
    "                       .replace('add','my_add').replace('sub','my_sub')\n",
    "                       .replace('mul','my_mul').replace('truediv','my_truediv')\n",
    "                       .replace('protected_div','my_protected_div')\n",
    "                       for plasmid in individual.plasmid]\n",
    "    \n",
    "    def my_add(a,b):\n",
    "\n",
    "        if isinstance(a,bool) or isinstance(b,bool):\n",
    "            return False\n",
    "        if isinstance(a,int) or isinstance(a,float):\n",
    "            a = Fraction(1)\n",
    "        if isinstance(b,int) or isinstance(b,float):\n",
    "            b = Fraction(1)\n",
    "\n",
    "        if a == b:\n",
    "            return a\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def my_sub(a,b):\n",
    "        \n",
    "        if isinstance(a,bool) or isinstance(b,bool):\n",
    "            return False\n",
    "        if isinstance(a,int) or isinstance(a,float):\n",
    "            a = Fraction(1)\n",
    "        if isinstance(b,int) or isinstance(b,float):\n",
    "            b = Fraction(1)\n",
    "\n",
    "        if a == b:\n",
    "            return a\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def my_mul(a,b):\n",
    "        \n",
    "        if isinstance(a,bool) or isinstance(b,bool):\n",
    "            return False\n",
    "        if isinstance(a,int) or isinstance(a,float):\n",
    "            a = Fraction(1)\n",
    "        if isinstance(b,int) or isinstance(b,float):\n",
    "            b = Fraction(1)\n",
    "            \n",
    "        return a * b\n",
    "\n",
    "    def my_truediv(a,b):\n",
    "        \n",
    "        if isinstance(a,bool) or isinstance(b,bool) or b == 0:\n",
    "            return False\n",
    "        if isinstance(a,int) or isinstance(a,float):\n",
    "            a = Fraction(1)\n",
    "        if isinstance(b,int) or isinstance(b,float):\n",
    "            b = Fraction(1)\n",
    "\n",
    "        return a / b\n",
    "\n",
    "    def my_protected_div(a,b):\n",
    "        \n",
    "        if isinstance(a,bool) or isinstance(b,bool) or b == 0:\n",
    "            return False\n",
    "        if isinstance(a,int) or isinstance(a,float):\n",
    "            a = Fraction(1)\n",
    "        if isinstance(b,int) or isinstance(b,float):\n",
    "            b = Fraction(1)\n",
    "\n",
    "        return a / b\n",
    "    \n",
    "    def my_p_(tensor):\n",
    "        if isinstance(tensor, bool):\n",
    "            return False\n",
    "        scalor = plasmid_library.pop(0)\n",
    "        scalor = eval(scalor, create_var)\n",
    "        return scalor * tensor\n",
    "\n",
    "        \n",
    "    create_var = locals()\n",
    "    create_var.update(dict_of_dimension)\n",
    "    namespace = {'my_add': my_add, 'my_sub': my_sub,'my_mul': my_mul,'my_truediv': my_truediv, 'my_protected_div': my_protected_div}\n",
    "    create_var.update(namespace)\n",
    "    \n",
    "    individual_expr = str(individual).replace('\\t','').replace('\\n','').replace('tensor_add','my_add').replace('tensor_sub','my_sub').replace('tensor_inner_prduct','my_mul').replace('p_','my_p_')\n",
    "    dimension_of_DDEq = eval(individual_expr)\n",
    "    if dimension_of_DDEq == target_dimension:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "toolbox.register('compile',my_compile)\n",
    "toolbox.register('dimensional_verification',dimensional_verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a222ec-a494-436a-bb20-8dcb339a8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Define the loss function\n",
    "\n",
    "# Register the dimensional verification operation\n",
    "# Define the fitness for individuals that apply the linear scaling technique\n",
    "def evaluate(individual):\n",
    "    \"\"\"\n",
    "    First verify whether the individuals satisfy dimensional homogeneity.\n",
    "    If it is not dimensional homogeneous, we would identify it as an invalid individual and directly assign a significant error to it.\n",
    "    Otherwise, we would apply linear scaling (ls) to the individual, \n",
    "    and then evaluate its loss: MRE (mean relative error)\n",
    "    \"\"\"\n",
    "    validity = toolbox.dimensional_verification(individual, dict_of_dimension, target_dimension)\n",
    "    if not validity:\n",
    "        return -1.,\n",
    "    else:\n",
    "        Yp = Y_pretend(individual)\n",
    "        print(individual)\n",
    "        print(individual.plasmid[0])\n",
    "        print(individual.plasmid[1])\n",
    "        print(Yp)\n",
    "        if isinstance(Yp, np.ndarray):\n",
    "            sum = 0\n",
    "            for k in range(Y.shape[0]):\n",
    "                y = Y[k]\n",
    "                yp = Yp[k]\n",
    "                sum += (\n",
    "                    (y[0][0] * yp[0][0] + y[0][1] * yp[0][1] + y[1][0] * yp[1][0] + y[1][1] * yp[1][1]) / \n",
    "                    (      (abs((y[0][0])**2 + 2 * y[0][1] * y[1][0] + (y[1][1])**2)**0.5) *\n",
    "                    (abs((yp[0][0])**2 + 2 * yp[0][1] * yp[1][0] + (yp[1][1])**2)**0.5)     )\n",
    "                )\n",
    "            fitness = sum / Y.shape[0]\n",
    "            print(fitness)\n",
    "            return fitness,\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"type of Yp must be np.ndarray.\")\n",
    "\n",
    "# todo: ls-evaluate\n",
    "toolbox.register('evaluate', evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35743678-d799-4340-8963-e0e0ea60e894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Register genetic operators\n",
    "toolbox.register('select', tools.selTournament, tournsize=2) # Selection operator\n",
    "# 1. general operators\n",
    "toolbox.register('mut_uniform', gep.mutate_uniform, pset=host_pset, ind_pb=0.05, pb=1)\n",
    "toolbox.register('mut_invert', gep.invert, pb=0.1)\n",
    "toolbox.register('mut_is_transpose', gep.is_transpose, pb=0.1)\n",
    "toolbox.register('mut_ris_transpose', gep.ris_transpose, pb=0.1)\n",
    "# toolbox.register('mut_gene_transpose', gep.gene_transpose, pb=0.1)\n",
    "toolbox.register('cx_1p', gep.crossover_one_point, pb=0.3)\n",
    "toolbox.register('cx_2p', gep.crossover_two_point, pb=0.2)\n",
    "toolbox.register('cx_gene', gep.crossover_gene, pb=0.1)\n",
    "# 2. Dc-specific operators\n",
    "toolbox.register('mutdc_dc', gep.mutate_uniform_dc, ind_pb=0.05, pb=1)\n",
    "toolbox.register('mutdc_invert_dc', gep.invert_dc, pb=0.1)\n",
    "toolbox.register('mutdc_transpose_dc', gep.transpose_dc, pb=0.1)\n",
    "toolbox.register('mutdc_rnc_array_dc', gep.mutate_rnc_array_dc, rnc_gen=toolbox.rnc_gen, ind_pb='0.5p')\n",
    "toolbox.pbs['mutdc_rnc_array_dc'] = 1 \n",
    "\n",
    "# %% Statistics to be inspected\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "stats.register(\"avg\", np.mean)\n",
    "# stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "# %% Launch evolution\n",
    "\n",
    "# Define size of population and number of generations\n",
    "n_pop = 5000             # Number of individuals in a host_population\n",
    "n_gen = 1000000             # Maximum Generation\n",
    "tol = 1e-4               # Threshold to terminate the evolution\n",
    "output_type = 'Constitutive_equation_of_Newtonian_fluid'     # Name of the problem\n",
    "isRestart = False        # 'True'/'False' for initializing the population with given/random individuals.\n",
    "\n",
    "# If isRestart is 'True', read the given .pkl file to load the individuals as the first generation population.\n",
    "# If isRestart is 'False', initialize the first generation population with random individuals.\n",
    "if isRestart:\n",
    "    with open(\"pkl/Constitutive_equation_of_Newtonian_fluid.pkl\",'rb') as file:\n",
    "        host_pop  = pickle.loads(file.read())\n",
    "        for ind in host_pop:\n",
    "            print(ind)\n",
    "else:\n",
    "    host_pop = toolbox.host_population(n=n_pop) \n",
    "    plasmid_pop = toolbox.plasmid_population(host_pop)\n",
    "    for ind_host, ind_plasmid in zip(host_pop, plasmid_pop):\n",
    "        ind_host.plasmid = ind_plasmid \n",
    "\n",
    "# Only record the best three individuals ever found in all generations\n",
    "champs = 3 \n",
    "hof = tools.HallOfFame(champs)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b3aa448-97f4-4979-b3b4-4c9ea7be3acf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\tavg\tmin\tmax\n",
      "0  \t5000  \t-1 \t-1 \t-1 \n",
      "1  \t4999  \t-1 \t-1 \t-1 \n",
      "2  \t4999  \t-1 \t-1 \t-1 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evolve\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 3\u001b[0m pop, log \u001b[38;5;241m=\u001b[39m dm\u001b[38;5;241m.\u001b[39mgep_simple(host_pop, plasmid_pop, toolbox, n_generations\u001b[38;5;241m=\u001b[39mn_gen, n_elites\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      4\u001b[0m                           stats\u001b[38;5;241m=\u001b[39mstats, hall_of_fame\u001b[38;5;241m=\u001b[39mhof, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,tolerance \u001b[38;5;241m=\u001b[39m tol,GEP_type \u001b[38;5;241m=\u001b[39m output_type)\n",
      "File \u001b[1;32m~\\DHC-MGEP\\DHC_MGEP.py:240\u001b[0m, in \u001b[0;36mgep_simple\u001b[1;34m(host_population, plasmid_population, toolbox, n_generations, n_elites, stats, hall_of_fame, verbose, tolerance, GEP_type)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# # Termination criterion of error reducing velocity\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# # Compute the best individual every 500 generations, if the best \u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# # one is the same with that of the 500 generations before, \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# replication \u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# toolbox.clone() is copy.deepcopy()\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m offspring \u001b[38;5;241m=\u001b[39m [toolbox\u001b[38;5;241m.\u001b[39mclone(ind) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m offspring]\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# mutation\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m toolbox\u001b[38;5;241m.\u001b[39mpbs:\n",
      "File \u001b[1;32m~\\DHC-MGEP\\DHC_MGEP.py:240\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# # Termination criterion of error reducing velocity\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;66;03m# # Compute the best individual every 500 generations, if the best \u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# # one is the same with that of the 500 generations before, \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# replication \u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# toolbox.clone() is copy.deepcopy()\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m offspring \u001b[38;5;241m=\u001b[39m [toolbox\u001b[38;5;241m.\u001b[39mclone(ind) \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m offspring]\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# mutation\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m toolbox\u001b[38;5;241m.\u001b[39mpbs:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 271\u001b[0m         state \u001b[38;5;241m=\u001b[39m deepcopy(state, memo)\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    273\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    229\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m deepcopy(value, memo)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(x, memo)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:206\u001b[0m, in \u001b[0;36m_deepcopy_list\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    204\u001b[0m append \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mappend\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m x:\n\u001b[1;32m--> 206\u001b[0m     append(deepcopy(a, memo))\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:288\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m listiter:\n\u001b[1;32m--> 288\u001b[0m         item \u001b[38;5;241m=\u001b[39m deepcopy(item, memo)\n\u001b[0;32m    289\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m _reconstruct(x, memo, \u001b[38;5;241m*\u001b[39mrv)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:288\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m listiter:\n\u001b[1;32m--> 288\u001b[0m         item \u001b[38;5;241m=\u001b[39m deepcopy(item, memo)\n\u001b[0;32m    289\u001b[0m         y\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ProgramData\\anaconda3\\Lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m copier(memo)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\geppy\\core\\symbol.py:89\u001b[0m, in \u001b[0;36mPrimitive.__deepcopy__\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m(name=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, arity=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marity)\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__deepcopy__\u001b[39m(\u001b[38;5;28mself\u001b[39m, memodict):\n\u001b[0;32m     90\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    Faster deep copy because generally a primitive is immutable except the ephemeral terminals\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    The derived classes should rewrite this method if needed.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evolve\n",
    "start_time = time.time()\n",
    "pop, log = dm.gep_simple(host_pop, plasmid_pop, toolbox, n_generations=n_gen, n_elites=1,\n",
    "                          stats=stats, hall_of_fame=hof, verbose=True,tolerance = tol,GEP_type = output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2e8cb-35f7-46f7-97f8-fb16fd4dfba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
